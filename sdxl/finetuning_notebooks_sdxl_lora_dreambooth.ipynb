{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "ðŸ“Œ **This notebook has been updated in [jhj0517/finetuning-notebooks](https://github.com/jhj0517/finetuning-notebooks) repository!**\n",
        "\n",
        "## Version : 1.0.0\n",
        "---"
      ],
      "metadata": {
        "id": "doKhBBXIfS21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #(Optional) Check GPU\n",
        "\n",
        "#@markdown To train SDXL lora at least 12GB VRAM is recommended.\n",
        "#@markdown <br> And you need at least 16GB for CPU RAM, which is unfortunately not available on the free tier in Colab.\n",
        "#@markdown <br>You can check your GPU setup before start.\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "23yZvUlagEsx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kNbSbsctxahq",
        "cellView": "form",
        "outputId": "5bd6bb22-20a0-4bde-f0fd-d74529ae9b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 100693, done.\u001b[K\n",
            "remote: Counting objects: 100% (534/534), done.\u001b[K\n",
            "remote: Compressing objects: 100% (297/297), done.\u001b[K\n",
            "remote: Total 100693 (delta 405), reused 253 (delta 227), pack-reused 100159 (from 3)\u001b[K\n",
            "Receiving objects: 100% (100693/100693), 75.07 MiB | 19.06 MiB/s, done.\n",
            "Resolving deltas: 100% (74292/74292), done.\n",
            "/content/diffusers\n",
            "Obtaining file:///content/diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.35.0.dev0) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.35.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.35.0.dev0) (0.34.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.35.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.35.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.35.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.35.0.dev0) (0.6.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.35.0.dev0) (11.3.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.35.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.35.0.dev0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.35.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.35.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.35.0.dev0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.34.0->diffusers==0.35.0.dev0) (1.1.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers==0.35.0.dev0) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.35.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.35.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.35.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.35.0.dev0) (2025.8.3)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building editable for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.35.0.dev0-0.editable-py3-none-any.whl size=11370 sha256=09a2ceb5b9be19a429252d79657533e66e7cdbbc3a115ed833b7cf087c289dd6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vh0hxzk5/wheels/30/15/ca/ab6e88c89d6ba7047b3f155894c6c346e7cf06067fd132ae62\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.34.0\n",
            "    Uninstalling diffusers-0.34.0:\n",
            "      Successfully uninstalled diffusers-0.34.0\n",
            "Successfully installed diffusers-0.35.0.dev0\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.3.1\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "#@title #1. Install Dependencies\n",
        "#@markdown This notebook is powered by https://github.com/huggingface/diffusers\n",
        "!git clone https://github.com/huggingface/diffusers\n",
        "%cd diffusers\n",
        "!pip install -e .\n",
        "\n",
        "# Cherry picked dependencies from https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/requirements_sdxl.txt to use in Colab.\n",
        "!pip install ftfy\n",
        "!pip install datasets\n",
        "!pip install bitsandbytes\n",
        "# Only install this if you want to use optimization with xformers.\n",
        "# !pip install xformers\n",
        "\n",
        "\n",
        "# Comment on the requirements above, and uncomment below if you're not using Colab.\n",
        "# !pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126\n",
        "# !pip install deepspeed\n",
        "# !pip install accelerate>=0.22.0\n",
        "# !pip install transformers>=4.25.1\n",
        "# !pip install ftfy\n",
        "# !pip install tensorboard\n",
        "# !pip install Jinja2\n",
        "# !pip install datasets\n",
        "# !pip install peft==0.7.0\n",
        "# !pip install xformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 2. (Optional) Mount Google Drive\n",
        "\n",
        "#@markdown It's not mandatory but it's recommended to mount to Google Drive and use the Google Drive's path for your training image dataset.\n",
        "\n",
        "#@markdown The dataset should have following structure:\n",
        "\n",
        "#@markdown This notebook uses diffuser's dreambooth LoRA training, you only need image files in the dataset with this way.\n",
        "\n",
        "#@markdown ### Example File Structure (Image Files Only):\n",
        "#@markdown ```\n",
        "#@markdown your-dataset/\n",
        "#@markdown â”œâ”€â”€ a (1).png         # Image file\n",
        "#@markdown â”œâ”€â”€ a (2).png         # Another image file\n",
        "#@markdown â”œâ”€â”€ a (3).png         # Another image file\n",
        "#@markdown ```\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M1bu3MpsACOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d788812-1028-4e56-9f31-eaedbbbcecc3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 3. (Optional) Register Huggingface Token To Download Base Model\n",
        "\n",
        "#@markdown If you don't have entire base model files ([stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/tree/main)) in the drive you need to sign in to Huggingface to download the model.\n",
        "\n",
        "#@markdown Get your tokens from https://huggingface.co/settings/tokens, and register it in colab's seceret as **`HF_TOKEN`** and use it in any notebook. ( 'Read' permission is enough )\n",
        "\n",
        "#@markdown To register secrets in colab, click on the key-shaped icon in the left panel and enter your **`HF_TOKEN`** like this:\n",
        "\n",
        "#@markdown ![image](https://media.githubusercontent.com/media/jhj0517/finetuning-notebooks/master/docs/screenshots/colab_secrets.png)\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "\n",
        "print(\"HF_TOKEN environment variable has been set.\")"
      ],
      "metadata": {
        "id": "9WzQRwZij5jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5193dc0-fe11-43b8-d884-918f15c17603",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF_TOKEN environment variable has been set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 4. Train with Parameters\n",
        "import os\n",
        "import toml\n",
        "import json\n",
        "import re\n",
        "\n",
        "#@markdown ## Paths Configuration\n",
        "DATASET_DIR = \"/content/drive/MyDrive/myface\" # @param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/sdxl/outputs\" # @param {type:\"string\"}\n",
        "OUTPUT_NAME = \"My-SDXL-LoRA-V1\" # @param {type:\"string\"}\n",
        "\n",
        "OUTPUT_DIR = os.path.join(OUTPUT_DIR, OUTPUT_NAME)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "#@markdown ## Base Model Configuration\n",
        "BASE_MODEL_PATH_OR_ID = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param {type:\"string\"}\n",
        "BASE_VAE_PATH_OR_ID = \"madebyollin/sdxl-vae-fp16-fix\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Dataset Configuration\n",
        "# CAPTION_EXTENSION = \".txt\" # @param {type:\"string\"}\n",
        "RESOLUTION = 1024 # @param {type:\"integer\"}\n",
        "# CAPTION_COLUMN = \"text\"\n",
        "\n",
        "#@markdown ## Training Settings\n",
        "MIXED_PRECISION = \"bf16\" # @param [\"no\", \"fp16\", \"bf16\"]\n",
        "INSTANCE_PROMPT = \"a mia girl\" # @param {type:\"string\"}\n",
        "RANDOM_FLIP = True # @param {type:\"boolean\"}\n",
        "TRAIN_BATCH_SIZE = 1 # @param {type:\"integer\"}\n",
        "MAX_TRAIN_STEPS = 1000 # @param {type:\"integer\"}\n",
        "CHECKPOINTING_STEPS = 1 # @param {type:\"integer\"}\n",
        "LEARNING_RATE = 1e-4 # @param {type:\"number\"}\n",
        "LR_SCHEDULER = \"constant\" # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]\n",
        "LR_WARMUP_STEPS = 0 # @param {type:\"integer\"}\n",
        "GRADIENT_ACCUMULATION_STEPS = 4 # @param {type:\"integer\"}\n",
        "SEED = 77 # @param {type:\"integer\"}\n",
        "GRADIENT_CHECKPOINTING = True # @param {type:\"boolean\"}\n",
        "USE_8_BIT_ADAM = True # @param {type:\"boolean\"}\n",
        "# ENABLE_XFORMERS_MEMORY_EFFICIENT_ATTENTION = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ## Network Settings\n",
        "RANK = 4 # @param {type:\"integer\"}\n",
        "\n",
        "\n",
        "#@markdown ## Validation Configuration\n",
        "#@markdown WandB is a 3rd party service, to use it you need to get an API key from https://wandb.ai/authorize.\n",
        "ENABLE_WANDB = False # @param {type:\"boolean\"}\n",
        "VALIDATION_PROMPT = \"mia is cute\"  # @param {type:\"string\"}\n",
        "# NUM_VALIDATION_IMAGES = 4 # @param {type:\"integer\"}\n",
        "VALIDATION_EPOCHS = 25 # @param {type:\"integer\"}\n",
        "\n",
        "# Write Command\n",
        "command_parts = [\n",
        "    \"accelerate\", \"launch\",\n",
        "    \"\\\"/content/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py\\\"\",\n",
        "]\n",
        "\n",
        "command_parts.extend([\n",
        "    f\"--pretrained_model_name_or_path=\\\"{BASE_MODEL_PATH_OR_ID}\\\"\",\n",
        "    f\"--pretrained_vae_model_name_or_path=\\\"{BASE_VAE_PATH_OR_ID}\\\"\",\n",
        "    f\"--instance_data_dir=\\\"{DATASET_DIR}\\\"\",\n",
        "    f\"--instance_prompt=\\\"{INSTANCE_PROMPT}\\\"\",\n",
        "#    f\"--caption_column={CAPTION_COLUMN}\",\n",
        "    f\"--mixed_precision={MIXED_PRECISION}\",\n",
        "    f\"--resolution={RESOLUTION}\",\n",
        "    f\"--max_train_steps={MAX_TRAIN_STEPS}\",\n",
        "    f\"--train_batch_size={TRAIN_BATCH_SIZE}\",\n",
        "    f\"--checkpointing_steps={CHECKPOINTING_STEPS}\",\n",
        "    f\"--learning_rate={LEARNING_RATE}\",\n",
        "    f\"--lr_scheduler={LR_SCHEDULER}\",\n",
        "    f\"--lr_warmup_steps={LR_WARMUP_STEPS}\",\n",
        "    f\"--seed={SEED}\",\n",
        "    f\"--output_dir={OUTPUT_DIR}\",\n",
        "    f\"--validation_prompt=\\\"{VALIDATION_PROMPT}\\\"\",\n",
        "#    f\"--num_validation_images={NUM_VALIDATION_IMAGES}\",\n",
        "    f\"--validation_epochs={VALIDATION_EPOCHS}\",\n",
        "    f\"--gradient_accumulation_steps={GRADIENT_ACCUMULATION_STEPS}\",\n",
        "    f\"--rank={RANK}\",\n",
        "\n",
        "])\n",
        "\n",
        "if RANDOM_FLIP:\n",
        "    command_parts.append(\"--random_flip\")\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    command_parts.append(\"--report_to=\\\"wandb\\\"\")\n",
        "\n",
        "if GRADIENT_CHECKPOINTING:\n",
        "    command_parts.append(\"--gradient_checkpointing\")\n",
        "\n",
        "if USE_8_BIT_ADAM:\n",
        "    command_parts.append(\"--use_8bit_adam\")\n",
        "\n",
        "# if ENABLE_XFORMERS_MEMORY_EFFICIENT_ATTENTION:\n",
        "#     command_parts.append(\"--enable_xformers_memory_efficient_attention\")\n",
        "\n",
        "# Write metadata.jsonl for the dataset\n",
        "def create_metadata_jsonl(dataset_dir, caption_extension=\".txt\"):\n",
        "    metadata = []\n",
        "    image_files = [f for f in os.listdir(dataset_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        base_name = os.path.splitext(image_file)[0]\n",
        "        caption_file = f\"{base_name}{caption_extension}\"\n",
        "\n",
        "        if os.path.exists(os.path.join(dataset_dir, caption_file)):\n",
        "            try:\n",
        "                with open(os.path.join(dataset_dir, caption_file), \"r\", encoding=\"utf-8\") as f:\n",
        "                    caption = f.read().strip()\n",
        "\n",
        "                match = re.search(r\"\\((\\d+)\\)\", base_name)\n",
        "                if match:\n",
        "                    file_number = int(match.group(1))\n",
        "                    new_file_name = f\"{file_number:04d}.png\"\n",
        "                else:\n",
        "                    file_number = len(metadata) + 1\n",
        "                    new_file_name = f\"{file_number:04d}.png\"\n",
        "\n",
        "                metadata.append({\"file_name\": new_file_name, \"text\": caption})\n",
        "\n",
        "                os.rename(os.path.join(dataset_dir, image_file), os.path.join(dataset_dir, new_file_name))\n",
        "                os.rename(os.path.join(dataset_dir, caption_file), os.path.join(dataset_dir, f\"{file_number:04d}{caption_extension}\"))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {image_file}: {e}\")\n",
        "        else:\n",
        "            print(f\"Warning: Caption file {caption_file} not found for {image_file}\")\n",
        "\n",
        "    metadata_path = os.path.join(dataset_dir, \"metadata.jsonl\")\n",
        "    with open(metadata_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "        for item in metadata:\n",
        "            json.dump(item, outfile, ensure_ascii=False)\n",
        "            outfile.write(\"\\n\")\n",
        "\n",
        "# Diffuser's script does not use each caption with dreambooth.\n",
        "# create_metadata_jsonl(DATASET_DIR, CAPTION_EXTENSION)\n",
        "# print(f\"{os.path.join(DATASET_DIR, 'metadata.jsonl')} has written.\")\n",
        "\n",
        "# Train\n",
        "!accelerate config default\n",
        "command = \" \".join(command_parts)\n",
        "print(command)\n",
        "!{command}"
      ],
      "metadata": {
        "id": "fob2cRMQeW5C",
        "cellView": "form",
        "outputId": "c92337d8-bb86-4d30-a6a7-f144a8bf0bab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration already exists at /root/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n",
            "accelerate launch \"/content/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py\" --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" --instance_data_dir=\"/content/drive/MyDrive/myface\" --instance_prompt=\"a mia girl\" --mixed_precision=bf16 --resolution=1024 --max_train_steps=1000 --train_batch_size=1 --checkpointing_steps=1 --learning_rate=0.0001 --lr_scheduler=constant --lr_warmup_steps=0 --seed=77 --output_dir=/content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1 --validation_prompt=\"mia is cute\" --validation_epochs=25 --gradient_accumulation_steps=4 --rank=4 --random_flip --gradient_checkpointing --use_8bit_adam\n",
            "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\n",
            "2025-08-09 01:29:05.926996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754702946.201328    5531 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754702946.278734    5531 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754702946.843603    5531 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754702946.843669    5531 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754702946.843675    5531 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754702946.843679    5531 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-09 01:29:06.895047: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "tokenizer_config.json: 100% 737/737 [00:00<00:00, 4.43MB/s]\n",
            "vocab.json: 1.06MB [00:00, 9.57MB/s]\n",
            "merges.txt: 525kB [00:00, 1.70MB/s] \n",
            "special_tokens_map.json: 100% 472/472 [00:00<00:00, 3.01MB/s]\n",
            "tokenizer_config.json: 100% 725/725 [00:00<00:00, 5.22MB/s]\n",
            "special_tokens_map.json: 100% 460/460 [00:00<00:00, 3.43MB/s]\n",
            "config.json: 100% 565/565 [00:00<00:00, 4.40MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "config.json: 100% 575/575 [00:00<00:00, 3.65MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "model_index.json: 100% 609/609 [00:00<00:00, 3.87MB/s]\n",
            "scheduler_config.json: 100% 479/479 [00:00<00:00, 3.77MB/s]\n",
            "{'thresholding', 'rescale_betas_zero_snr', 'clip_sample_range', 'dynamic_thresholding_ratio', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
            "text_encoder/model.safetensors: 100% 492M/492M [00:09<00:00, 54.4MB/s]\n",
            "text_encoder_2/model.safetensors: 100% 2.78G/2.78G [00:32<00:00, 84.6MB/s]\n",
            "config.json: 100% 631/631 [00:00<00:00, 3.91MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 205MB/s]\n",
            "{'latents_mean', 'mid_block_add_attention', 'shift_factor', 'use_post_quant_conv', 'use_quant_conv', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing AutoencoderKL.\n",
            "\n",
            "All the weights of AutoencoderKL were initialized from the model checkpoint at madebyollin/sdxl-vae-fp16-fix.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.\n",
            "config.json: 1.68kB [00:00, 1.51MB/s]\n",
            "unet/diffusion_pytorch_model.safetensors:  14% 1.48G/10.3G [00:23<01:04, 137MB/s]  \u001b[2m2025-08-09T01:30:45.052938Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mStatus Code: 504. Retrying..., \u001b[1;33mrequest_id\u001b[0m\u001b[33m: \"\"\u001b[0m\n",
            "    \u001b[2;3mat\u001b[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:207\n",
            "\n",
            "  \u001b[2m2025-08-09T01:30:45.056042Z\u001b[0m \u001b[33m WARN\u001b[0m  \u001b[33mRetry attempt #0. Sleeping 905.312844ms before the next attempt\u001b[0m\n",
            "    \u001b[2;3mat\u001b[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171\n",
            "\n",
            "unet/diffusion_pytorch_model.safetensors: 100% 10.3G/10.3G [04:08<00:00, 41.4MB/s]\n",
            "{'dropout', 'attention_type', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.\n",
            "All model checkpoint weights were used when initializing UNet2DConditionModel.\n",
            "\n",
            "All the weights of UNet2DConditionModel were initialized from the model checkpoint at stabilityai/stable-diffusion-xl-base-1.0.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.\n",
            "Steps:   0% 1/1000 [00:39<11:04:38, 39.92s/it, loss=0.324, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-1/pytorch_lora_weights.safetensors\n",
            "Steps:   0% 2/1000 [01:21<11:16:47, 40.69s/it, loss=0.267, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-2/pytorch_lora_weights.safetensors\n",
            "Steps:   0% 3/1000 [02:03<11:28:39, 41.44s/it, loss=0.0835, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-3/pytorch_lora_weights.safetensors\n",
            "Steps:   0% 4/1000 [02:46<11:37:51, 42.04s/it, loss=0.0857, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-4/pytorch_lora_weights.safetensors\n",
            "Steps:   0% 5/1000 [03:29<11:45:12, 42.53s/it, loss=0.297, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-5/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 6/1000 [04:12<11:47:27, 42.70s/it, loss=0.0804, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-6/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 7/1000 [04:56<11:49:41, 42.88s/it, loss=0.0026, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-7/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 8/1000 [05:18<10:00:52, 36.34s/it, loss=0.0138, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-8/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 8/1000 [05:19<10:00:52, 36.34s/it, loss=0.0991, lr=0.0001]\n",
            "Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦):   0% 0.00/335M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦):  20% 66.4M/335M [00:01<00:07, 34.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦):  40% 133M/335M [00:08<00:14, 13.7MB/s] \u001b[A\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦):  60% 201M/335M [00:12<00:08, 15.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦):  80% 268M/335M [00:13<00:03, 21.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "vae_1_0/diffusion_pytorch_model.safetens(â€¦): 100% 335M/335M [00:18<00:00, 17.6MB/s]\n",
            "\n",
            "Fetching 11 files: 100% 11/11 [00:19<00:00,  1.74s/it]\n",
            "{'image_encoder', 'feature_extractor'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:00<00:00, 16.77it/s]\u001b[A{'sigma_max', 'use_exponential_sigmas', 'rescale_betas_zero_snr', 'timestep_type', 'sigma_min', 'final_sigmas_type', 'use_beta_sigmas'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00, 45.97it/s]\n",
            "{'use_lu_lambdas', 'euler_at_final', 'flow_shift', 'thresholding', 'use_exponential_sigmas', 'variance_type', 'rescale_betas_zero_snr', 'use_flow_sigmas', 'solver_order', 'algorithm_type', 'time_shift_type', 'final_sigmas_type', 'dynamic_thresholding_ratio', 'lambda_min_clipped', 'lower_order_final', 'use_dynamic_shifting', 'use_beta_sigmas', 'solver_type'} was not found in config. Values will be initialized to default values.\n",
            "Steps:   1% 9/1000 [28:31<126:46:31, 460.54s/it, loss=0.366, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-9/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 10/1000 [29:14<91:12:52, 331.69s/it, loss=0.316, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-10/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 11/1000 [29:58<66:53:04, 243.46s/it, loss=0.0551, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-11/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 12/1000 [30:41<50:06:36, 182.59s/it, loss=0.306, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-12/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 13/1000 [31:24<38:29:30, 140.40s/it, loss=0.0187, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-13/pytorch_lora_weights.safetensors\n",
            "Steps:   1% 14/1000 [32:08<30:24:44, 111.04s/it, loss=0.00353, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-14/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 15/1000 [32:51<24:48:25, 90.67s/it, loss=0.222, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-15/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 16/1000 [33:13<19:09:00, 70.06s/it, loss=0.00627, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-16/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 17/1000 [33:57<16:57:04, 62.08s/it, loss=0.197, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-17/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 18/1000 [34:40<15:23:41, 56.44s/it, loss=0.0052, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-18/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 19/1000 [35:24<14:20:05, 52.60s/it, loss=0.00398, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-19/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 20/1000 [36:07<13:33:34, 49.81s/it, loss=0.101, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-20/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 21/1000 [36:51<13:01:07, 47.87s/it, loss=0.0267, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-21/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 22/1000 [37:34<12:37:55, 46.50s/it, loss=0.0379, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-22/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 23/1000 [38:17<12:21:20, 45.53s/it, loss=0.108, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-23/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 24/1000 [38:40<10:28:19, 38.63s/it, loss=0.118, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-24/pytorch_lora_weights.safetensors\n",
            "Steps:   2% 25/1000 [39:23<10:51:18, 40.08s/it, loss=0.0566, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-25/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 26/1000 [40:06<11:06:28, 41.06s/it, loss=0.0342, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-26/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 27/1000 [40:50<11:18:12, 41.82s/it, loss=0.329, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-27/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 28/1000 [41:33<11:24:37, 42.26s/it, loss=0.0429, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-28/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 29/1000 [42:17<11:29:29, 42.61s/it, loss=0.341, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-29/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 30/1000 [43:00<11:32:05, 42.81s/it, loss=0.0149, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-30/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 31/1000 [43:43<11:33:47, 42.96s/it, loss=0.0738, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-31/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 32/1000 [44:05<9:52:32, 36.73s/it, loss=0.0458, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-32/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 33/1000 [44:49<10:23:34, 38.69s/it, loss=0.0135, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-33/pytorch_lora_weights.safetensors\n",
            "Steps:   3% 34/1000 [45:32<10:45:52, 40.12s/it, loss=0.00177, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-34/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 35/1000 [46:16<11:01:18, 41.12s/it, loss=0.187, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-35/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 36/1000 [46:59<11:11:00, 41.76s/it, loss=0.00582, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-36/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 37/1000 [47:42<11:18:06, 42.25s/it, loss=0.325, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-37/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 38/1000 [48:26<11:22:17, 42.55s/it, loss=0.275, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-38/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 39/1000 [49:09<11:25:06, 42.78s/it, loss=0.0121, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-39/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 40/1000 [49:31<9:45:30, 36.59s/it, loss=0.133, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-40/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 41/1000 [50:14<10:16:44, 38.59s/it, loss=0.038, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-41/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 42/1000 [50:58<10:38:42, 40.00s/it, loss=0.11, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-42/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 43/1000 [51:41<10:54:00, 41.00s/it, loss=0.139, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-43/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 44/1000 [52:24<11:03:55, 41.67s/it, loss=0.116, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-44/pytorch_lora_weights.safetensors\n",
            "Steps:   4% 45/1000 [53:07<11:10:25, 42.12s/it, loss=0.00788, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-45/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 46/1000 [53:51<11:15:11, 42.46s/it, loss=0.0177, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-46/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 47/1000 [54:34<11:18:27, 42.71s/it, loss=0.00796, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-47/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 48/1000 [54:56<9:39:47, 36.54s/it, loss=0.0783, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-48/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 49/1000 [55:39<10:11:28, 38.58s/it, loss=0.0926, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-49/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 50/1000 [56:23<10:33:00, 39.98s/it, loss=0.141, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-50/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 51/1000 [57:06<10:48:17, 40.99s/it, loss=0.123, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-51/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 52/1000 [57:49<10:58:14, 41.66s/it, loss=0.336, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-52/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 53/1000 [58:32<11:05:05, 42.14s/it, loss=0.0613, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-53/pytorch_lora_weights.safetensors\n",
            "Steps:   5% 54/1000 [59:16<11:09:52, 42.49s/it, loss=0.0669, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-54/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 55/1000 [59:59<11:12:56, 42.73s/it, loss=0.294, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-55/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 56/1000 [1:00:21<9:35:04, 36.55s/it, loss=0.00605, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-56/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 57/1000 [1:01:04<10:06:03, 38.56s/it, loss=0.0211, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-57/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 58/1000 [1:01:48<10:27:58, 40.00s/it, loss=0.0474, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-58/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 59/1000 [1:02:31<10:42:35, 40.97s/it, loss=0.0628, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-59/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 60/1000 [1:03:14<10:52:27, 41.65s/it, loss=0.0313, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-60/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 61/1000 [1:03:57<10:59:00, 42.11s/it, loss=0.298, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-61/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 62/1000 [1:04:41<11:03:44, 42.46s/it, loss=0.00793, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-62/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 63/1000 [1:05:24<11:06:44, 42.69s/it, loss=0.196, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-63/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 64/1000 [1:05:46<9:30:11, 36.55s/it, loss=0.0421, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-64/pytorch_lora_weights.safetensors\n",
            "Steps:   6% 65/1000 [1:06:30<10:02:24, 38.66s/it, loss=0.19, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-65/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 66/1000 [1:07:13<10:23:36, 40.06s/it, loss=0.166, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-66/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 67/1000 [1:07:56<10:37:54, 41.02s/it, loss=0.033, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-67/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 68/1000 [1:08:40<10:48:03, 41.72s/it, loss=0.125, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-68/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 69/1000 [1:09:23<10:55:38, 42.25s/it, loss=0.0816, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-69/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 70/1000 [1:10:06<10:59:51, 42.57s/it, loss=0.0365, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-70/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 71/1000 [1:10:50<11:02:50, 42.81s/it, loss=0.198, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-71/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 72/1000 [1:11:12<9:26:23, 36.62s/it, loss=0.043, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-72/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 73/1000 [1:11:55<9:57:18, 38.66s/it, loss=0.0221, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-73/pytorch_lora_weights.safetensors\n",
            "Steps:   7% 74/1000 [1:12:39<10:18:08, 40.05s/it, loss=0.00261, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-74/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 75/1000 [1:13:22<10:32:35, 41.03s/it, loss=0.00155, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-75/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 76/1000 [1:14:05<10:42:22, 41.71s/it, loss=0.0279, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-76/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 77/1000 [1:14:49<10:49:17, 42.21s/it, loss=0.00238, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-77/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 78/1000 [1:15:32<10:54:50, 42.61s/it, loss=0.0376, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-78/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 79/1000 [1:16:16<10:57:49, 42.86s/it, loss=0.309, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-79/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 80/1000 [1:16:38<9:22:21, 36.68s/it, loss=0.0337, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-80/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 81/1000 [1:17:22<9:53:24, 38.74s/it, loss=0.287, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-81/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 82/1000 [1:18:05<10:13:25, 40.09s/it, loss=0.0379, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-82/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 83/1000 [1:18:48<10:27:50, 41.08s/it, loss=0.174, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-83/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 84/1000 [1:19:31<10:36:46, 41.71s/it, loss=0.00782, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-84/pytorch_lora_weights.safetensors\n",
            "Steps:   8% 85/1000 [1:20:15<10:43:28, 42.19s/it, loss=0.163, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-85/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 86/1000 [1:20:58<10:48:15, 42.55s/it, loss=0.0975, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-86/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 87/1000 [1:21:41<10:50:46, 42.77s/it, loss=0.0542, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-87/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 88/1000 [1:22:03<9:15:59, 36.58s/it, loss=0.00881, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-88/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 89/1000 [1:22:47<9:45:49, 38.58s/it, loss=0.0311, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-89/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 90/1000 [1:23:30<10:06:17, 39.98s/it, loss=0.324, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-90/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 91/1000 [1:24:13<10:20:40, 40.97s/it, loss=0.0155, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-91/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 92/1000 [1:24:56<10:30:15, 41.65s/it, loss=0.0635, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-92/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 93/1000 [1:25:40<10:36:38, 42.12s/it, loss=0.0279, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-93/pytorch_lora_weights.safetensors\n",
            "Steps:   9% 94/1000 [1:26:23<10:41:50, 42.51s/it, loss=0.268, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-94/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 95/1000 [1:27:06<10:45:07, 42.77s/it, loss=0.018, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-95/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 96/1000 [1:27:29<9:10:59, 36.57s/it, loss=0.119, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-96/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 97/1000 [1:28:12<9:41:54, 38.67s/it, loss=0.0191, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-97/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 98/1000 [1:28:55<10:02:12, 40.06s/it, loss=0.0873, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-98/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 99/1000 [1:29:39<10:15:54, 41.02s/it, loss=0.00554, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-99/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 100/1000 [1:30:22<10:25:06, 41.67s/it, loss=0.207, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-100/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 101/1000 [1:31:05<10:31:48, 42.17s/it, loss=0.0956, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-101/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 102/1000 [1:31:48<10:35:05, 42.43s/it, loss=0.472, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-102/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 103/1000 [1:32:32<10:38:13, 42.69s/it, loss=0.134, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-103/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 104/1000 [1:32:54<9:06:11, 36.58s/it, loss=0.119, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-104/pytorch_lora_weights.safetensors\n",
            "Steps:  10% 105/1000 [1:33:37<9:35:22, 38.57s/it, loss=0.0036, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-105/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 106/1000 [1:34:21<9:56:30, 40.03s/it, loss=0.269, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-106/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 107/1000 [1:35:04<10:10:12, 41.00s/it, loss=0.301, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-107/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 108/1000 [1:35:47<10:19:22, 41.66s/it, loss=0.00151, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-108/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 109/1000 [1:36:30<10:25:35, 42.13s/it, loss=0.00321, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-109/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 110/1000 [1:37:13<10:30:03, 42.48s/it, loss=0.0545, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-110/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 111/1000 [1:37:57<10:33:07, 42.73s/it, loss=0.011, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-111/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 112/1000 [1:38:19<9:00:45, 36.54s/it, loss=0.00503, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-112/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 113/1000 [1:39:02<9:29:19, 38.51s/it, loss=0.0995, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-113/pytorch_lora_weights.safetensors\n",
            "Steps:  11% 114/1000 [1:39:45<9:49:52, 39.95s/it, loss=0.246, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-114/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 115/1000 [1:40:29<10:04:18, 40.97s/it, loss=0.104, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-115/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 116/1000 [1:41:12<10:15:51, 41.80s/it, loss=0.0218, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-116/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 117/1000 [1:41:56<10:22:28, 42.30s/it, loss=0.00241, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-117/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 118/1000 [1:42:39<10:26:13, 42.60s/it, loss=0.338, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-118/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 119/1000 [1:43:22<10:28:20, 42.79s/it, loss=0.163, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-119/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 120/1000 [1:43:45<8:56:53, 36.61s/it, loss=0.211, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-120/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 121/1000 [1:44:28<9:26:34, 38.67s/it, loss=0.0448, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-121/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 122/1000 [1:45:11<9:46:14, 40.06s/it, loss=0.0223, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-122/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 123/1000 [1:45:55<9:59:37, 41.02s/it, loss=0.337, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-123/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 124/1000 [1:46:38<10:10:55, 41.84s/it, loss=0.087, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-124/pytorch_lora_weights.safetensors\n",
            "Steps:  12% 125/1000 [1:47:22<10:16:33, 42.28s/it, loss=0.00417, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-125/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 126/1000 [1:48:05<10:20:12, 42.58s/it, loss=0.0435, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-126/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 127/1000 [1:48:48<10:22:27, 42.78s/it, loss=0.29, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-127/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 128/1000 [1:49:10<8:52:13, 36.62s/it, loss=0.173, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-128/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 129/1000 [1:49:54<9:21:13, 38.66s/it, loss=0.266, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-129/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 130/1000 [1:50:37<9:40:54, 40.06s/it, loss=0.274, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-130/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 131/1000 [1:51:20<9:53:56, 41.01s/it, loss=0.114, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-131/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 132/1000 [1:52:04<10:04:52, 41.81s/it, loss=0.027, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-132/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 133/1000 [1:52:48<10:10:55, 42.28s/it, loss=0.288, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-133/pytorch_lora_weights.safetensors\n",
            "Steps:  13% 134/1000 [1:53:31<10:14:42, 42.59s/it, loss=0.0079, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-134/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 135/1000 [1:54:14<10:16:38, 42.77s/it, loss=0.0241, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-135/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 136/1000 [1:54:36<8:46:36, 36.57s/it, loss=0.195, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-136/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 137/1000 [1:55:19<9:15:14, 38.60s/it, loss=0.0207, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-137/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 138/1000 [1:56:03<9:34:53, 40.02s/it, loss=0.136, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-138/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 139/1000 [1:56:46<9:48:34, 41.02s/it, loss=0.0703, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-139/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 140/1000 [1:57:29<9:57:32, 41.69s/it, loss=0.00176, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-140/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 141/1000 [1:58:13<10:03:37, 42.16s/it, loss=0.0352, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-141/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 142/1000 [1:58:56<10:07:47, 42.50s/it, loss=0.0258, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-142/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 143/1000 [1:59:39<10:10:51, 42.77s/it, loss=0.0377, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-143/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 144/1000 [2:00:01<8:41:51, 36.58s/it, loss=0.00224, lr=0.0001] Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-144/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 145/1000 [2:00:45<9:10:45, 38.65s/it, loss=0.113, lr=0.0001]Model weights saved in /content/drive/MyDrive/sdxl/outputs/My-SDXL-LoRA-V1/checkpoint-145/pytorch_lora_weights.safetensors\n",
            "Steps:  14% 145/1000 [2:01:18<9:10:45, 38.65s/it, loss=0.0132, lr=0.0001]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # 5. (Optional) Test your LoRA\n",
        "\n",
        "from huggingface_hub.repocard import RepoCard\n",
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "BASE_MODEL_PATH_OR_ID = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param {type:\"string\"}\n",
        "YOUR_LORA_PATH = \"/content/drive/MyDrive/finetuning-notebooks/sdxl/outputs/something/pytorch_lora_weights.safetensors\" # @param {type:\"string\"}\n",
        "PROMPT = \"A picture of a sks dog in a bucket\" # @param {type:\"string\"}\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(BASE_MODEL_PATH_OR_ID, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(YOUR_LORA_PATH)\n",
        "image = pipe(PROMPT, num_inference_steps=25).images[0]\n",
        "image.save(\"sks_dog.png\")\n",
        "\n",
        "from IPython.display import display\n",
        "display(image)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PALmQfvtSk6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}